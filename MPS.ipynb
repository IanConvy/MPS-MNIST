{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59a4e95",
   "metadata": {},
   "source": [
    "Most libraries built for multi-dimensional array operations can be used to implement tensor networks:\n",
    "\n",
    "* Numpy (Python)\n",
    "* PyTorch (Python)\n",
    "* TensorFlow (Python)\n",
    "* iTensor (C++, Julia)\n",
    "\n",
    "There are also libraries such as TensorNetwork which are backend-agnostic wrappers that allow you to utilize tensor network formalisms when working with e.g. Numpy. I've found that the performance of these wrapper isn't good enough yet to use for ML. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13cb4c9",
   "metadata": {},
   "source": [
    "# Training an MPS classifier on MNIST using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3027c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TensorFlow libraries that we will use\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58bb3f",
   "metadata": {},
   "source": [
    "## Implementing the product-state feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fb4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherit from the Keras Layer class\n",
    "class ProductMap(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Embed each feature \"x\" into vector [1 - x, x] and stack into a batch x features x 2 array\n",
    "        output_1 = tf.vectorized_map(lambda x: 1-x, inputs)\n",
    "        output_2 = tf.vectorized_map(lambda x: x, inputs)\n",
    "        feature_matrix = tf.stack([output_1, output_2], axis = 2)\n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420f80e",
   "metadata": {},
   "source": [
    "## Impementing the MPS layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39a1a2",
   "metadata": {},
   "source": [
    "![title](mps_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61dfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPS_Layer(layers.Layer):\n",
    "\n",
    "    def __init__(self, num_sites, bond_dim, num_output, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_half = num_sites // 2\n",
    "        \n",
    "        # Create variables for tensors to the left, right, and center of output site\n",
    "        self.left = self.add_weight(\"left\", shape = [2, self.n_half, bond_dim, bond_dim])\n",
    "        self.right = self.add_weight(\"right\", shape = [2, self.n_half, bond_dim, bond_dim])\n",
    "        self.middle = self.add_weight(\"middle\", shape = [num_output, bond_dim, bond_dim])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        left = tf.einsum(\"slij,bls->lbij\", self.left, inputs[:, :self.n_half]) # Contract left tensors with data\n",
    "        right = tf.einsum(\"slij,bls->lbij\", self.right, inputs[:, self.n_half:]) # Contract right tensors with data\n",
    "        left = self.reduction(left) # Contract left tensors together\n",
    "        right = self.reduction(right) # Contract right tensors together\n",
    "        outputs = tf.einsum(\"bij,cjk,bki->bc\", left, self.middle, right) # Contract left and right with center\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def reduction(tensor):\n",
    "        # Takes a vector of matrices and contracts them together as a single product\n",
    "        size = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover = tensor[nice_size:]\n",
    "            tensor = tf.matmul(tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            tensor = tf.concat([tensor, leftover], axis = 0)\n",
    "            size = half_size + int(size % 2 == 1)\n",
    "        return tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78455177",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8337341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images are retrieved, flattened, and normalized to the range [0, 1], labels are one-hot encoded\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape([60000, 28*28]) / 255\n",
    "x_test = x_test.reshape([10000, 28*28]) / 255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259bebd",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae12e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = x_train.shape[1]\n",
    "bond_dim = 20\n",
    "\n",
    "# Combine the ProductMap and MPS Layers into a sequential Keras model\n",
    "model = Sequential()\n",
    "model.add(ProductMap())\n",
    "model.add(MPS_Layer(num_features, bond_dim, 10))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "      optimizer=tf.keras.optimizers.RMSprop(0.0001),\n",
    "      metrics=['accuracy'],\n",
    "      run_eagerly = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6941212",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa88c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 12s 21ms/step - loss: 2.3026 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.0980\n",
      "Epoch 6/12\n",
      " 88/469 [====>.........................] - ETA: 7s - loss: 2.3026 - accuracy: 0.1013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3c12398ca67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0502e80",
   "metadata": {},
   "source": [
    "## Well that didn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f57cf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPS_Layer_Improved(layers.Layer):\n",
    "\n",
    "    def __init__(self, num_sites, bond_dim, num_output, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_half = num_sites // 2\n",
    "        \n",
    "        # Create variables for tensors to the left, right, and center of output site\n",
    "        self.left = self.add_weight(\"left\", initializer = self.initializer, shape = [2, self.n_half, bond_dim, bond_dim])\n",
    "        self.right = self.add_weight(\"right\", initializer = self.initializer, shape = [2, self.n_half, bond_dim, bond_dim])\n",
    "        self.middle = self.add_weight(\"middle\", initializer = self.initializer, shape = [1, num_output, bond_dim, bond_dim])[0]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        left = tf.einsum(\"slij,bls->lbij\", self.left, inputs[:, :self.n_half]) # Contract left tensors with data\n",
    "        right = tf.einsum(\"slij,bls->lbij\", self.right, inputs[:, self.n_half:]) # Contract right tensors with data\n",
    "        left = self.reduction(left) # Contract left tensors together\n",
    "        right = self.reduction(right) # Contract right tensors together\n",
    "        outputs = tf.einsum(\"bij,cjk,bki->bc\", left, self.middle, right) # Contract left and right with center\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def initializer(shape, dtype):\n",
    "        # Tensors need to be initialized such that they basically act like the identity\n",
    "        (phys_dim, num_sites, bond_dim, bond_dim) = shape\n",
    "        matrices = phys_dim * num_sites*[tf.eye(bond_dim)]\n",
    "        weights = tf.reshape(tf.stack(matrices_2), [phys_dim, num_sites, bond_dim, bond_dim])\n",
    "        noised = weights + tf.random.normal(weights.shape, 0, 1e-2)\n",
    "        return noised\n",
    "    \n",
    "    @staticmethod\n",
    "    def reduction(tensor):\n",
    "        # Takes a vector of matrices and contracts them together as a single product\n",
    "        size = int(tensor.shape[0])\n",
    "        while size > 1:\n",
    "            half_size = size // 2\n",
    "            nice_size = 2 * half_size\n",
    "            leftover = tensor[nice_size:]\n",
    "            tensor = tf.matmul(tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
    "            tensor = tf.concat([tensor, leftover], axis = 0)\n",
    "            size = half_size + int(size % 2 == 1)\n",
    "        return tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c817fc",
   "metadata": {},
   "source": [
    "## Let's try this again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe1e687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = x_train.shape[1]\n",
    "bond_dim = 20\n",
    "\n",
    "# Combine the ProductMap and MPS Layers into a sequential Keras model\n",
    "model = Sequential()\n",
    "model.add(ProductMap())\n",
    "model.add(MPS_Layer_Improved(num_features, bond_dim, 10))\n",
    "\n",
    "# Compile\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
    "      optimizer=tf.keras.optimizers.RMSprop(0.0001),\n",
    "      metrics=['accuracy'],\n",
    "      run_eagerly = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48d3707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.0844 - val_accuracy: 0.9786\n",
      "Epoch 2/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.0808 - val_accuracy: 0.9825\n",
      "Epoch 3/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.1130 - val_accuracy: 0.9778\n",
      "Epoch 4/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.1083 - val_accuracy: 0.9753\n",
      "Epoch 5/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.1030 - val_accuracy: 0.9807\n",
      "Epoch 6/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.1322 - val_accuracy: 0.9762\n",
      "Epoch 7/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.0785 - val_accuracy: 0.9805\n",
      "Epoch 8/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.1596 - val_accuracy: 0.9773\n",
      "Epoch 9/25\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.0981 - val_accuracy: 0.9826\n",
      "Epoch 10/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.1217 - val_accuracy: 0.9805\n",
      "Epoch 11/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.1277 - val_accuracy: 0.9824\n",
      "Epoch 12/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.1050 - val_accuracy: 0.9827\n",
      "Epoch 13/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.0960 - val_accuracy: 0.9808\n",
      "Epoch 14/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.1023 - val_accuracy: 0.9814\n",
      "Epoch 15/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1778 - val_accuracy: 0.9820\n",
      "Epoch 16/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.1180 - val_accuracy: 0.9809\n",
      "Epoch 17/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.1111 - val_accuracy: 0.9805\n",
      "Epoch 18/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.2116 - val_accuracy: 0.9734\n",
      "Epoch 19/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1600 - val_accuracy: 0.9802\n",
      "Epoch 20/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0217 - accuracy: 0.9963 - val_loss: 0.1305 - val_accuracy: 0.9775\n",
      "Epoch 21/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.1088 - val_accuracy: 0.9819\n",
      "Epoch 22/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.1442 - val_accuracy: 0.9794\n",
      "Epoch 23/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.1159 - val_accuracy: 0.9796\n",
      "Epoch 24/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.1194 - val_accuracy: 0.9814\n",
      "Epoch 25/25\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.1515 - val_accuracy: 0.9813\n",
      "Test loss: 0.15149736404418945\n",
      "Test accuracy: 0.9812999963760376\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
